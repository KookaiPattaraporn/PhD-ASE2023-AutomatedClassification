{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ps642/Desktop/cnn/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Moodle_reg_level'\n",
    "\n",
    "trainingSize = 60\n",
    "validationSize = 20\n",
    "testSize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv of the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 74)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/ps642/Desktop/cnn/Moodle_reg_level.csv'\n",
    "data_path\n",
    "data = pd.read_csv(data_path, encoding = \"ISO-8859-1\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDL-61275</td>\n",
       "      <td>Collection of issues that capture the changes ...</td>\n",
       "      <td>To be released as a plugin with subsequent int...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDL-61297</td>\n",
       "      <td>A new popup for showing the policy links to gu...</td>\n",
       "      <td>If enabled, show guest users a popup (similar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MDL-61302</td>\n",
       "      <td>Add the workflow for allowing users to agree t...</td>\n",
       "      <td>Change the workflow for allowing users to agre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Issue ID                                            summary  \\\n",
       "0  MDL-61275  Collection of issues that capture the changes ...   \n",
       "1  MDL-61297  A new popup for showing the policy links to gu...   \n",
       "2  MDL-61302  Add the workflow for allowing users to agree t...   \n",
       "\n",
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  To be released as a plugin with subsequent int...   0   0   0   0   0   0   \n",
       "1  If enabled, show guest users a popup (similar ...   0   0   0   0   0   0   \n",
       "2  Change the workflow for allowing users to agre...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unused columns and concat summary and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ps642\\AppData\\Local\\Temp\\ipykernel_10456\\2784066759.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data = data.drop('summary',1)\n",
      "C:\\Users\\ps642\\AppData\\Local\\Temp\\ipykernel_10456\\2784066759.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data = data.drop('Issue ID',1)\n"
     ]
    }
   ],
   "source": [
    "data['description'] = data['summary'] + \" \" + data['description']\n",
    "data = data.drop('summary',1) \n",
    "data = data.drop('Issue ID',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collection of issues that capture the changes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A new popup for showing the policy links to gu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the workflow for allowing users to agree t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  Collection of issues that capture the changes ...   0   0   0   0   0   0   \n",
       "1  A new popup for showing the policy links to gu...   0   0   0   0   0   0   \n",
       "2  Add the workflow for allowing users to agree t...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collection of issues that capture the changes required to the user sign up process to comply with GDPR To be released as a plugin with subsequent integration into core for Moodle 3.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Total size: 478\n",
      "#Training : 286, #Validation : 95, #Testing : 95\n",
      "Total: 476\n"
     ]
    }
   ],
   "source": [
    "if trainingSize + validationSize + testSize == 100:\n",
    "  numData = len(data)\n",
    "  numTrain = int((trainingSize * numData) / 100)\n",
    "  numValidation = int((validationSize * numData) / 100)\n",
    "  numTest = int((testSize * numData) / 100)\n",
    "\n",
    "  print(\"#Total size: %s\" % numData)\n",
    "  print(\"#Training : %s, #Validation : %s, #Testing : %s\" % (numTrain, numValidation, numTest))\n",
    "  print(\"Total: %s\" % (numTrain + numValidation + numTest))\n",
    "\n",
    "  firstStop = numTrain\n",
    "  secondStop = numTrain + numValidation\n",
    "else:\n",
    "  print(\"input not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train  validate  test\n",
      "0        1         0     0\n",
      "1        1         0     0\n",
      "2        1         0     0\n",
      "3        1         0     0\n",
      "4        1         0     0\n",
      "..     ...       ...   ...\n",
      "473      0         0     1\n",
      "474      0         0     1\n",
      "475      0         0     1\n",
      "476      0         0     1\n",
      "477      0         0     1\n",
      "\n",
      "[478 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "divided_set = np.zeros([numData, 3]).astype(int)\n",
    "divided_set[0:firstStop, 0] = 1\n",
    "divided_set[firstStop:secondStop, 1] = 1\n",
    "divided_set[secondStop:numData, 2] = 1\n",
    "experimentalSet = pd.DataFrame(divided_set, columns = ['train', 'validate', 'test'])\n",
    "print(experimentalSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set index: 286\n",
      "Validation set index: 95\n",
      "Test set index: 97\n"
     ]
    }
   ],
   "source": [
    "trainSetIndex = experimentalSet['train'].value_counts()[1]\n",
    "validSetIndex = experimentalSet['validate'].value_counts()[1]\n",
    "testSetIndex = experimentalSet['test'].value_counts()[1]\n",
    "print(\"Training set index: \" + str(trainSetIndex))\n",
    "print(\"Validation set index: \" + str(validSetIndex))\n",
    "print(\"Test set index: \" + str(testSetIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSetData = data.iloc[:trainSetIndex, :]\n",
    "validSetData = data.iloc[trainSetIndex:trainSetIndex + validSetIndex, :]\n",
    "testSetData = data.iloc[trainSetIndex + validSetIndex:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collection of issues that capture the changes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A new popup for showing the policy links to gu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the workflow for allowing users to agree t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  Collection of issues that capture the changes ...   0   0   0   0   0   0   \n",
       "1  A new popup for showing the policy links to gu...   0   0   0   0   0   0   \n",
       "2  Add the workflow for allowing users to agree t...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "trainSetData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Allow devolved selection of purposes and categ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Add ability to configure data registry to use ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Make data registry available to users Minimum ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  R1  R2  R3  R4  R5  \\\n",
       "286  Allow devolved selection of purposes and categ...   0   0   0   0   0   \n",
       "287  Add ability to configure data registry to use ...   0   0   0   0   0   \n",
       "288  Make data registry available to users Minimum ...   1   0   0   0   0   \n",
       "\n",
       "     R6  R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "286   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "287   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "288   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation set:\")\n",
    "validSetData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Erroneous query in enrol_paypal\\privacy\\provid...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Add support for removal of context users - enr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Add support for removal of context users - enr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  R1  R2  R3  R4  R5  \\\n",
       "381  Erroneous query in enrol_paypal\\privacy\\provid...   1   0   0   0   0   \n",
       "382  Add support for removal of context users - enr...   0   0   0   0   0   \n",
       "383  Add support for removal of context users - enr...   0   0   0   0   0   \n",
       "\n",
       "     R6  R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "381   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "382   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "383   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"testset:\")\n",
    "testSetData.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wording embedding layer using pretrained model from Google's word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.0.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.16.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = trainSetData.description\n",
    "validText = validSetData.description\n",
    "testText = testSetData.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2365 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=300000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'', lower=True)\n",
    "tokenizer.fit_on_texts(trainText)\n",
    "trainSequences = tokenizer.texts_to_sequences(trainText)\n",
    "validSequences = tokenizer.texts_to_sequences(validText)\n",
    "testSequences = tokenizer.texts_to_sequences(testText)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train and X validation tensor: (286, 540) (95, 540)\n",
      "Shape of label train and validation tensor: (286, 71) (95, 71)\n",
      "Shape of X test: (97, 540)\n",
      "Shape of label test tensor: (97, 71)\n"
     ]
    }
   ],
   "source": [
    "x_train = pad_sequences(trainSequences)\n",
    "y_train = trainSetData.iloc[:,1:].values\n",
    "\n",
    "x_valid = pad_sequences(validSequences, maxlen = x_train.shape[1])\n",
    "y_valid = validSetData.iloc[:,1:].values\n",
    "\n",
    "x_test = pad_sequences(testSequences,maxlen = x_train.shape[1])\n",
    "y_test = testSetData.iloc[:,1:].values\n",
    "\n",
    "print('Shape of X train and X validation tensor:', x_train.shape, x_valid.shape)\n",
    "print('Shape of label train and validation tensor:', y_train.shape, y_valid.shape)\n",
    "\n",
    "print('Shape of X test:', x_test.shape)\n",
    "print('Shape of label test tensor:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Google's pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.23.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(path + 'GoogleNews-vectors-negative300.bin.gz', \n",
    "                                                 binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word not found in pretrained w2v: 474\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM=300\n",
    "vocabulary_size = min(len(word_index)+1,NUM_WORDS) # minimum fo word index and num words\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "count_word_not_found = 0\n",
    "for word, i in word_index.items():\n",
    "  if i>=NUM_WORDS:\n",
    "    continue\n",
    "  try:\n",
    "    embedding_vector = word_vectors[word]\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "  except KeyError:\n",
    "    embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "    count_word_not_found = count_word_not_found + 1\n",
    "\n",
    "print(\"word not found in pretrained w2v: \" + str(count_word_not_found))\n",
    "# there are many words do not exist in google w2v. we random number for those words.\n",
    "\n",
    "del(word_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 540)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 540, 300)     709800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 540, 300, 1)  0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 538, 1, 100)  90100       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 537, 1, 100)  120100      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 536, 1, 100)  150100      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 1, 100)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 1, 100)    0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 300)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          38528       ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 71)           9159        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,117,787\n",
      "Trainable params: 1,117,787\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "                            \n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout, concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sequence_length = x_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(1,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=(1,1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((3*num_filters,))(flatten)\n",
    "\n",
    "fc_layer = Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "fc_dropout = Dropout(drop)(fc_layer)\n",
    "output = Dense(units=len(y_train[0]), activation='sigmoid', kernel_regularizer=regularizers.l2(0.01))(fc_dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ps642\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path_modelcheckpoint = path\n",
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(path_modelcheckpoint+project+'_ch_.hdf5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.4247 - acc: 0.0105\n",
      "Epoch 1: val_loss improved from inf to 3.25695, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 7s 3s/step - loss: 3.4247 - acc: 0.0105 - val_loss: 3.2570 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.2509 - acc: 0.0105\n",
      "Epoch 2: val_loss improved from 3.25695 to 3.08208, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 3.2509 - acc: 0.0105 - val_loss: 3.0821 - val_acc: 0.0211 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.0935 - acc: 0.0035\n",
      "Epoch 3: val_loss improved from 3.08208 to 2.92062, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.0935 - acc: 0.0035 - val_loss: 2.9206 - val_acc: 0.0316 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.9477 - acc: 0.0140\n",
      "Epoch 4: val_loss improved from 2.92062 to 2.76716, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.9477 - acc: 0.0140 - val_loss: 2.7672 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.8156 - acc: 0.0070\n",
      "Epoch 5: val_loss improved from 2.76716 to 2.62189, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 1s/step - loss: 2.8156 - acc: 0.0070 - val_loss: 2.6219 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.6887 - acc: 0.0140\n",
      "Epoch 6: val_loss improved from 2.62189 to 2.48610, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.6887 - acc: 0.0140 - val_loss: 2.4861 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5685 - acc: 0.0105\n",
      "Epoch 7: val_loss improved from 2.48610 to 2.35757, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 2.5685 - acc: 0.0105 - val_loss: 2.3576 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4444 - acc: 0.0280\n",
      "Epoch 8: val_loss improved from 2.35757 to 2.23585, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.4444 - acc: 0.0280 - val_loss: 2.2359 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3205 - acc: 0.0210\n",
      "Epoch 9: val_loss improved from 2.23585 to 2.12198, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 2.3205 - acc: 0.0210 - val_loss: 2.1220 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2134 - acc: 0.0280\n",
      "Epoch 10: val_loss improved from 2.12198 to 2.01605, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 2.2134 - acc: 0.0280 - val_loss: 2.0160 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1108 - acc: 0.0210\n",
      "Epoch 11: val_loss improved from 2.01605 to 1.91828, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 2.1108 - acc: 0.0210 - val_loss: 1.9183 - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0127 - acc: 0.0315\n",
      "Epoch 12: val_loss improved from 1.91828 to 1.82810, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.0127 - acc: 0.0315 - val_loss: 1.8281 - val_acc: 0.0947 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9151 - acc: 0.0629\n",
      "Epoch 13: val_loss improved from 1.82810 to 1.74410, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.9151 - acc: 0.0629 - val_loss: 1.7441 - val_acc: 0.2000 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8199 - acc: 0.0455\n",
      "Epoch 14: val_loss improved from 1.74410 to 1.66624, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 1.8199 - acc: 0.0455 - val_loss: 1.6662 - val_acc: 0.2000 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7392 - acc: 0.0699\n",
      "Epoch 15: val_loss improved from 1.66624 to 1.59371, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.7392 - acc: 0.0699 - val_loss: 1.5937 - val_acc: 0.2000 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6629 - acc: 0.0664\n",
      "Epoch 16: val_loss improved from 1.59371 to 1.52566, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 1.6629 - acc: 0.0664 - val_loss: 1.5257 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5788 - acc: 0.0944\n",
      "Epoch 17: val_loss improved from 1.52566 to 1.46154, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.5788 - acc: 0.0944 - val_loss: 1.4615 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5118 - acc: 0.1154\n",
      "Epoch 18: val_loss improved from 1.46154 to 1.40111, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 1.5118 - acc: 0.1154 - val_loss: 1.4011 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4447 - acc: 0.1364\n",
      "Epoch 19: val_loss improved from 1.40111 to 1.34402, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.4447 - acc: 0.1364 - val_loss: 1.3440 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3866 - acc: 0.1259\n",
      "Epoch 20: val_loss improved from 1.34402 to 1.28999, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.3866 - acc: 0.1259 - val_loss: 1.2900 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3274 - acc: 0.1399\n",
      "Epoch 21: val_loss improved from 1.28999 to 1.23846, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.3274 - acc: 0.1399 - val_loss: 1.2385 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2736 - acc: 0.1503\n",
      "Epoch 22: val_loss improved from 1.23846 to 1.18921, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.2736 - acc: 0.1503 - val_loss: 1.1892 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2201 - acc: 0.1538\n",
      "Epoch 23: val_loss improved from 1.18921 to 1.14199, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 1s/step - loss: 1.2201 - acc: 0.1538 - val_loss: 1.1420 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1722 - acc: 0.2133\n",
      "Epoch 24: val_loss improved from 1.14199 to 1.09680, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.1722 - acc: 0.2133 - val_loss: 1.0968 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1240 - acc: 0.1993\n",
      "Epoch 25: val_loss improved from 1.09680 to 1.05363, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.1240 - acc: 0.1993 - val_loss: 1.0536 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0764 - acc: 0.1469\n",
      "Epoch 26: val_loss improved from 1.05363 to 1.01231, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.0764 - acc: 0.1469 - val_loss: 1.0123 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0379 - acc: 0.1713\n",
      "Epoch 27: val_loss improved from 1.01231 to 0.97280, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 1.0379 - acc: 0.1713 - val_loss: 0.9728 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9954 - acc: 0.1538\n",
      "Epoch 28: val_loss improved from 0.97280 to 0.93507, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.9954 - acc: 0.1538 - val_loss: 0.9351 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9581 - acc: 0.1643\n",
      "Epoch 29: val_loss improved from 0.93507 to 0.89903, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.9581 - acc: 0.1643 - val_loss: 0.8990 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9245 - acc: 0.1154\n",
      "Epoch 30: val_loss improved from 0.89903 to 0.86510, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.9245 - acc: 0.1154 - val_loss: 0.8651 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8840 - acc: 0.1469\n",
      "Epoch 31: val_loss improved from 0.86510 to 0.83297, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.8840 - acc: 0.1469 - val_loss: 0.8330 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8540 - acc: 0.1014\n",
      "Epoch 32: val_loss improved from 0.83297 to 0.80249, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.8540 - acc: 0.1014 - val_loss: 0.8025 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8194 - acc: 0.1538\n",
      "Epoch 33: val_loss improved from 0.80249 to 0.77331, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.8194 - acc: 0.1538 - val_loss: 0.7733 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7893 - acc: 0.1748\n",
      "Epoch 34: val_loss improved from 0.77331 to 0.74538, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.7893 - acc: 0.1748 - val_loss: 0.7454 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7584 - acc: 0.1678\n",
      "Epoch 35: val_loss improved from 0.74538 to 0.71846, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7584 - acc: 0.1678 - val_loss: 0.7185 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7371 - acc: 0.1818\n",
      "Epoch 36: val_loss improved from 0.71846 to 0.69270, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7371 - acc: 0.1818 - val_loss: 0.6927 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7112 - acc: 0.1643\n",
      "Epoch 37: val_loss improved from 0.69270 to 0.66817, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.7112 - acc: 0.1643 - val_loss: 0.6682 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6826 - acc: 0.1469\n",
      "Epoch 38: val_loss improved from 0.66817 to 0.64482, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.6826 - acc: 0.1469 - val_loss: 0.6448 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6585 - acc: 0.1888\n",
      "Epoch 39: val_loss improved from 0.64482 to 0.62284, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.6585 - acc: 0.1888 - val_loss: 0.6228 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6364 - acc: 0.1993\n",
      "Epoch 40: val_loss improved from 0.62284 to 0.60200, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.6364 - acc: 0.1993 - val_loss: 0.6020 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6153 - acc: 0.1678\n",
      "Epoch 41: val_loss improved from 0.60200 to 0.58243, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.6153 - acc: 0.1678 - val_loss: 0.5824 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5936 - acc: 0.1818\n",
      "Epoch 42: val_loss improved from 0.58243 to 0.56406, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.5936 - acc: 0.1818 - val_loss: 0.5641 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5771 - acc: 0.1119\n",
      "Epoch 43: val_loss improved from 0.56406 to 0.54662, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.5771 - acc: 0.1119 - val_loss: 0.5466 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5584 - acc: 0.1853\n",
      "Epoch 44: val_loss improved from 0.54662 to 0.52983, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.5584 - acc: 0.1853 - val_loss: 0.5298 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5374 - acc: 0.1713\n",
      "Epoch 45: val_loss improved from 0.52983 to 0.51333, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.5374 - acc: 0.1713 - val_loss: 0.5133 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5245 - acc: 0.1818\n",
      "Epoch 46: val_loss improved from 0.51333 to 0.49766, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.5245 - acc: 0.1818 - val_loss: 0.4977 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5089 - acc: 0.2098\n",
      "Epoch 47: val_loss improved from 0.49766 to 0.48310, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.5089 - acc: 0.2098 - val_loss: 0.4831 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4923 - acc: 0.1783\n",
      "Epoch 48: val_loss improved from 0.48310 to 0.46909, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.4923 - acc: 0.1783 - val_loss: 0.4691 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4767 - acc: 0.1818\n",
      "Epoch 49: val_loss improved from 0.46909 to 0.45541, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.4767 - acc: 0.1818 - val_loss: 0.4554 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4654 - acc: 0.1748\n",
      "Epoch 50: val_loss improved from 0.45541 to 0.44260, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.4654 - acc: 0.1748 - val_loss: 0.4426 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4525 - acc: 0.1958\n",
      "Epoch 51: val_loss improved from 0.44260 to 0.43048, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 3s/step - loss: 0.4525 - acc: 0.1958 - val_loss: 0.4305 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4418 - acc: 0.2517\n",
      "Epoch 52: val_loss improved from 0.43048 to 0.41935, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.4418 - acc: 0.2517 - val_loss: 0.4194 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4276 - acc: 0.2448\n",
      "Epoch 53: val_loss improved from 0.41935 to 0.40882, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.4276 - acc: 0.2448 - val_loss: 0.4088 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4115 - acc: 0.2343\n",
      "Epoch 54: val_loss improved from 0.40882 to 0.39859, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.4115 - acc: 0.2343 - val_loss: 0.3986 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4082 - acc: 0.2203\n",
      "Epoch 55: val_loss improved from 0.39859 to 0.38892, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.4082 - acc: 0.2203 - val_loss: 0.3889 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3974 - acc: 0.2343\n",
      "Epoch 56: val_loss improved from 0.38892 to 0.37917, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.3974 - acc: 0.2343 - val_loss: 0.3792 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3861 - acc: 0.2378\n",
      "Epoch 57: val_loss improved from 0.37917 to 0.36997, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.3861 - acc: 0.2378 - val_loss: 0.3700 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3783 - acc: 0.2483\n",
      "Epoch 58: val_loss improved from 0.36997 to 0.36122, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.3783 - acc: 0.2483 - val_loss: 0.3612 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3661 - acc: 0.2902\n",
      "Epoch 59: val_loss improved from 0.36122 to 0.35343, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.3661 - acc: 0.2902 - val_loss: 0.3534 - val_acc: 0.2105 - lr: 0.0010\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3589 - acc: 0.2308\n",
      "Epoch 60: val_loss improved from 0.35343 to 0.34634, saving model to C:/Users/ps642/Desktop/cnn\\Moodle_reg_level_ch_.hdf5\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.3589 - acc: 0.2308 - val_loss: 0.3463 - val_acc: 0.2105 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x_train, y_train, batch_size=200, epochs=60, verbose=1, validation_data=(x_valid, y_valid), \n",
    "                             callbacks=[early_stopping, model_checkpoint, reduce_lr_loss])  # starts training\n",
    "\n",
    "#change epoch here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ps642/Desktop/cnn/training_history/\n"
     ]
    }
   ],
   "source": [
    "path_history = path_modelcheckpoint + 'training_history/'\n",
    "print(path_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "path_history = path_modelcheckpoint + 'training_history/'\n",
    "path_model_json = path_modelcheckpoint + 'model_structure/'\n",
    "path_model_weight = path_modelcheckpoint + 'model_weight/'\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(training_history.history) \n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = path_history+project+'_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# save the best model\n",
    "# save model structure\n",
    "model_json = model.to_json()\n",
    "with open(path_model_json+project+\"_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# save model weight\n",
    "model.save_weights(path_model_weight+project+\"_wieght.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a recommendation on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_log = path\n",
    "\n",
    "np.savetxt(path_log + project + \"_actual.csv\", y_test, delimiter=\",\")\n",
    "np.savetxt(path_log + project + \"_estimate.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, estimate, startK, stopK, stepK):\n",
    "    recall_k = []\n",
    "    for k in range(startK, stopK + 1, stepK):\n",
    "        if k == 0:\n",
    "            k = 1\n",
    "        m = len(actual)\n",
    "        sum_recall = 0.0\n",
    "        for j in range(len(actual)):\n",
    "            y_true = np.argwhere(actual[j])\n",
    "            y_pred = estimate[j].argsort()[-k:]\n",
    "            # print y_true\n",
    "            # print y_pred\n",
    "            intersect = (y_true == y_pred).sum()\n",
    "            # print intersect\n",
    "            # print (len(y_true))\n",
    "            # print intersect / float(len(y_true))\n",
    "            sum_recall = sum_recall + (intersect / float(len(y_true)))\n",
    "            # print sum_recall\n",
    "        recall_k.append(sum_recall / float(m))\n",
    "        # print m\n",
    "        print('Recall@' + str(k) + ': {:.4f}'.format(sum_recall / float(m)))\n",
    "    return recall_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project:Moodle_reg_level\n",
      "Recall@1: 0.1166\n",
      "Recall@2: 0.2925\n",
      "Recall@3: 0.3051\n",
      "Recall@4: 0.3848\n",
      "Recall@5: 0.4287\n",
      "Recall@6: 0.4851\n",
      "Recall@7: 0.6346\n",
      "Recall@8: 0.6707\n",
      "Recall@9: 0.6707\n",
      "Recall@10: 0.7222\n",
      "Recall@11: 0.7712\n",
      "Recall@12: 0.7789\n",
      "Recall@13: 0.8045\n",
      "Recall@14: 0.8277\n",
      "Recall@15: 0.8328\n",
      "Recall@16: 0.8328\n",
      "Recall@17: 0.8466\n",
      "Recall@18: 0.8564\n",
      "Recall@19: 0.8564\n",
      "Recall@20: 0.8696\n",
      "Recall@21: 0.8696\n",
      "Recall@22: 0.8696\n",
      "Recall@23: 0.8851\n",
      "Recall@24: 0.9057\n",
      "Recall@25: 0.9057\n",
      "Recall@26: 0.9057\n",
      "Recall@27: 0.9160\n",
      "Recall@28: 0.9211\n",
      "Recall@29: 0.9418\n",
      "Recall@30: 0.9438\n",
      "Recall@31: 0.9464\n",
      "Recall@32: 0.9464\n",
      "Recall@33: 0.9464\n",
      "Recall@34: 0.9464\n",
      "Recall@35: 0.9464\n",
      "Recall@36: 0.9464\n",
      "Recall@37: 0.9515\n",
      "Recall@38: 0.9536\n",
      "Recall@39: 0.9536\n",
      "Recall@40: 0.9536\n",
      "Recall@41: 0.9536\n",
      "Recall@42: 0.9742\n",
      "Recall@43: 0.9742\n",
      "Recall@44: 0.9742\n",
      "Recall@45: 0.9742\n",
      "Recall@46: 0.9897\n",
      "Recall@47: 0.9897\n",
      "Recall@48: 0.9897\n",
      "Recall@49: 0.9897\n",
      "Recall@50: 0.9897\n",
      "Recall@51: 0.9897\n",
      "Recall@52: 0.9897\n",
      "Recall@53: 0.9897\n",
      "Recall@54: 0.9897\n",
      "Recall@55: 0.9897\n",
      "Recall@56: 0.9897\n",
      "Recall@57: 0.9897\n",
      "Recall@58: 1.0000\n",
      "Recall@59: 1.0000\n",
      "Recall@60: 1.0000\n",
      "Recall@61: 1.0000\n",
      "Recall@62: 1.0000\n",
      "Recall@63: 1.0000\n",
      "Recall@64: 1.0000\n",
      "Recall@65: 1.0000\n",
      "Recall@66: 1.0000\n",
      "Recall@67: 1.0000\n",
      "Recall@68: 1.0000\n",
      "Recall@69: 1.0000\n",
      "Recall@70: 1.0000\n",
      "Recall@71: 1.0000\n"
     ]
    }
   ],
   "source": [
    "startK = 1\n",
    "stepK = 1\n",
    "stopK = 71\n",
    "\n",
    "print(\"Project:\" + project)\n",
    "\n",
    "path_output = path\n",
    "\n",
    "recall_k = recall(y_test, y_pred, startK, stopK, stepK)\n",
    "\n",
    "np.savetxt(path_output + project + \"_recall_\" + str(startK) + \"_\" + str(stopK)+ \"_v.csv\", recall_k, delimiter=\",\", fmt='%1.4f')\n",
    "with open(path_output + \"performance\" + \"_recall_\" + str(startK) + \"_\" + str(stopK)+ \".csv\", 'a') as myoutput:\n",
    "  myoutput.write(project + \",\" + \",\".join(map(str, recall_k)) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.1959',\n",
       " '0.2887',\n",
       " '0.2131',\n",
       " '0.2216',\n",
       " '0.2062',\n",
       " '0.2045',\n",
       " '0.1988',\n",
       " '0.1817',\n",
       " '0.1615',\n",
       " '0.1526',\n",
       " '0.1453',\n",
       " '0.1349',\n",
       " '0.1277',\n",
       " '0.1208',\n",
       " '0.1134',\n",
       " '0.1063',\n",
       " '0.1013',\n",
       " '0.0974',\n",
       " '0.0922',\n",
       " '0.0897',\n",
       " '0.0854',\n",
       " '0.0815',\n",
       " '0.0789',\n",
       " '0.0765',\n",
       " '0.0734',\n",
       " '0.0706',\n",
       " '0.0683',\n",
       " '0.0663',\n",
       " '0.0647',\n",
       " '0.0629',\n",
       " '0.0612',\n",
       " '0.0593',\n",
       " '0.0575',\n",
       " '0.0558',\n",
       " '0.0542',\n",
       " '0.0527',\n",
       " '0.0515',\n",
       " '0.0505',\n",
       " '0.0492',\n",
       " '0.0479',\n",
       " '0.0468',\n",
       " '0.0461',\n",
       " '0.0451',\n",
       " '0.0440',\n",
       " '0.0431',\n",
       " '0.0426',\n",
       " '0.0417',\n",
       " '0.0408',\n",
       " '0.0400',\n",
       " '0.0392',\n",
       " '0.0384',\n",
       " '0.0377',\n",
       " '0.0370',\n",
       " '0.0363',\n",
       " '0.0356',\n",
       " '0.0350',\n",
       " '0.0344',\n",
       " '0.0339',\n",
       " '0.0334',\n",
       " '0.0328',\n",
       " '0.0323',\n",
       " '0.0318',\n",
       " '0.0313',\n",
       " '0.0308',\n",
       " '0.0303',\n",
       " '0.0298',\n",
       " '0.0294',\n",
       " '0.0290',\n",
       " '0.0285',\n",
       " '0.0281',\n",
       " '0.0277']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = y_test \n",
    "estimate = y_pred\n",
    "\n",
    "def prepare_y(actual, estimate, k):\n",
    "    y_true = np.argwhere(actual)\n",
    "    y_pred = estimate.argsort()[-k:]\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "precision_at_k = []\n",
    "component_num = len(actual.T)\n",
    "\n",
    "for k in range(component_num):\n",
    "    sum_precision = 0.0\n",
    "    for j in range(len(actual)):\n",
    "        y_true, y_pred = prepare_y(actual[j], estimate[j], (k + 1))\n",
    "        relevant = (y_true == y_pred).sum()\n",
    "        total_recommended_item = k + 1\n",
    "        sum_precision = sum_precision + (float(relevant) / total_recommended_item)\n",
    "\n",
    "    precision_at_k.append('%.4f' % (sum_precision / len(actual)))\n",
    "    # print('Precision@K: {:.4f}'.format(sum_precision / len(actual)))\n",
    "\n",
    "print(\"Precision@k\")\n",
    "\n",
    "precision_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: Moodle_reg_level, Model: <keras.engine.functional.Functional object at 0x0000027E96A617E0>\n",
      "MAP: 0.249701 over 97.0000 issues\n"
     ]
    }
   ],
   "source": [
    "m = len(actual)\n",
    "sum = 0.0\n",
    "for j in range(len(actual)):\n",
    "    y_true = np.argwhere(actual[j])\n",
    "    tp = len(y_true)\n",
    "    psum = 0.0\n",
    "    for k in range(1, tp + 1):\n",
    "        y_pred = estimate[j].argsort()[-k:]\n",
    "        intersect = (y_true == y_pred).sum()\n",
    "        prec = intersect / float(k)\n",
    "        psum += prec\n",
    "    ap = psum / float(tp)\n",
    "    sum += ap\n",
    "mean_avg_prec = sum / float(m)\n",
    "print('Project: {}, Model: {}'.format(project, model))\n",
    "print('MAP: {:f} over {:.4f} issues'.format(mean_avg_prec, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: Moodle_reg_level, Model: <keras.engine.functional.Functional object at 0x0000027E96A617E0>\n",
      "MRR: 0.412458 over 97.0000 issues\n"
     ]
    }
   ],
   "source": [
    "sum_rr = 0.0\n",
    "m = len(actual)\n",
    "for j in range(len(actual)):\n",
    "    y_true = np.argwhere(actual[j])\n",
    "    y_pred = estimate[j].argsort()[::-1][:]\n",
    "    ranks = []\n",
    "    for idx, i in enumerate(y_pred):\n",
    "        if i in y_true:\n",
    "            ranks.append(idx + 1)\n",
    "    if len(ranks) > 0:\n",
    "        first = ranks[0]\n",
    "        rr = 1 / float(first)\n",
    "        sum_rr += rr\n",
    "mrr_score = sum_rr / float(m)\n",
    "print('Project: {}, Model: {}'.format(project, model))\n",
    "print('MRR: {:f} over {:.4f} issues'.format(mrr_score, m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
