{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ps642/Desktop/cnn/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Chrome_reg_level'\n",
    "\n",
    "trainingSize = 60\n",
    "validationSize = 20\n",
    "testSize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv of the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 74)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/ps642/Desktop/cnn/Chrome_reg_level.csv'\n",
    "data_path\n",
    "data = pd.read_csv(data_path, encoding = \"ISO-8859-1\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6311</td>\n",
       "      <td>Suggestion: Make Cookies \"Exempt\" from Deletion</td>\n",
       "      <td>Chrome Version : 2.0.156.1\\n\\nWhen clearing Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32142</td>\n",
       "      <td>Add hours in Clear Browsing Data Dialog</td>\n",
       "      <td>Chrome Version : 4.0.266.0\\n\\n\\nWhat is the ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32985</td>\n",
       "      <td>Delete browsing data dialog is too small</td>\n",
       "      <td>Chrome Version : 4.0.302.2\\nURLs (if applicabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Issue ID                                          summary  \\\n",
       "0      6311  Suggestion: Make Cookies \"Exempt\" from Deletion   \n",
       "1     32142          Add hours in Clear Browsing Data Dialog   \n",
       "2     32985         Delete browsing data dialog is too small   \n",
       "\n",
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  Chrome Version : 2.0.156.1\\n\\nWhen clearing Co...   0   0   0   0   0   0   \n",
       "1  Chrome Version : 4.0.266.0\\n\\n\\nWhat is the ex...   0   0   0   0   0   0   \n",
       "2  Chrome Version : 4.0.302.2\\nURLs (if applicabl...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unused columns and concat summary and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ps642\\AppData\\Local\\Temp\\ipykernel_6100\\2784066759.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data = data.drop('summary',1)\n",
      "C:\\Users\\ps642\\AppData\\Local\\Temp\\ipykernel_6100\\2784066759.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data = data.drop('Issue ID',1)\n"
     ]
    }
   ],
   "source": [
    "data['description'] = data['summary'] + \" \" + data['description']\n",
    "data = data.drop('summary',1) \n",
    "data = data.drop('Issue ID',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suggestion: Make Cookies \"Exempt\" from Deletio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add hours in Clear Browsing Data Dialog Chrome...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delete browsing data dialog is too small Chrom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  Suggestion: Make Cookies \"Exempt\" from Deletio...   0   0   0   0   0   0   \n",
       "1  Add hours in Clear Browsing Data Dialog Chrome...   0   0   0   0   0   0   \n",
       "2  Delete browsing data dialog is too small Chrom...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suggestion: Make Cookies \"Exempt\" from Deletion Chrome Version : 2.0.156.1\\n\\nWhen clearing Cookies, there should be an option to make\\ncertain cookies, or cookies from a certain domain \"Exempt\" from the\\ndeletion. This could be a useful\\nfeature for people who want to remove ad-related cookies, Et Cetera, but not\\ncookies from sites that they trust. This would be similar to Internet\\nExplorer\\'s trusted sites, and security zones.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Total size: 896\n",
      "#Training : 537, #Validation : 179, #Testing : 179\n",
      "Total: 895\n"
     ]
    }
   ],
   "source": [
    "if trainingSize + validationSize + testSize == 100:\n",
    "  numData = len(data)\n",
    "  numTrain = int((trainingSize * numData) / 100)\n",
    "  numValidation = int((validationSize * numData) / 100)\n",
    "  numTest = int((testSize * numData) / 100)\n",
    "\n",
    "  print(\"#Total size: %s\" % numData)\n",
    "  print(\"#Training : %s, #Validation : %s, #Testing : %s\" % (numTrain, numValidation, numTest))\n",
    "  print(\"Total: %s\" % (numTrain + numValidation + numTest))\n",
    "\n",
    "  firstStop = numTrain\n",
    "  secondStop = numTrain + numValidation\n",
    "else:\n",
    "  print(\"input not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train  validate  test\n",
      "0        1         0     0\n",
      "1        1         0     0\n",
      "2        1         0     0\n",
      "3        1         0     0\n",
      "4        1         0     0\n",
      "..     ...       ...   ...\n",
      "891      0         0     1\n",
      "892      0         0     1\n",
      "893      0         0     1\n",
      "894      0         0     1\n",
      "895      0         0     1\n",
      "\n",
      "[896 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "divided_set = np.zeros([numData, 3]).astype(int)\n",
    "divided_set[0:firstStop, 0] = 1\n",
    "divided_set[firstStop:secondStop, 1] = 1\n",
    "divided_set[secondStop:numData, 2] = 1\n",
    "experimentalSet = pd.DataFrame(divided_set, columns = ['train', 'validate', 'test'])\n",
    "print(experimentalSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set index: 537\n",
      "Validation set index: 179\n",
      "Test set index: 180\n"
     ]
    }
   ],
   "source": [
    "trainSetIndex = experimentalSet['train'].value_counts()[1]\n",
    "validSetIndex = experimentalSet['validate'].value_counts()[1]\n",
    "testSetIndex = experimentalSet['test'].value_counts()[1]\n",
    "print(\"Training set index: \" + str(trainSetIndex))\n",
    "print(\"Validation set index: \" + str(validSetIndex))\n",
    "print(\"Test set index: \" + str(testSetIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSetData = data.iloc[:trainSetIndex, :]\n",
    "validSetData = data.iloc[trainSetIndex:trainSetIndex + validSetIndex, :]\n",
    "testSetData = data.iloc[trainSetIndex + validSetIndex:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suggestion: Make Cookies \"Exempt\" from Deletio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add hours in Clear Browsing Data Dialog Chrome...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delete browsing data dialog is too small Chrom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  R1  R2  R3  R4  R5  R6  \\\n",
       "0  Suggestion: Make Cookies \"Exempt\" from Deletio...   0   0   0   0   0   0   \n",
       "1  Add hours in Clear Browsing Data Dialog Chrome...   0   0   0   0   0   0   \n",
       "2  Delete browsing data dialog is too small Chrom...   0   0   0   0   0   0   \n",
       "\n",
       "   R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "trainSetData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Add metrics for the notices about other forms ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Failure of Chrome to delete user history in An...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>Removing History Item does not impact \"Recentl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  R1  R2  R3  R4  R5  \\\n",
       "537  Add metrics for the notices about other forms ...   0   0   0   0   0   \n",
       "538  Failure of Chrome to delete user history in An...   0   0   0   0   0   \n",
       "539  Removing History Item does not impact \"Recentl...   0   0   0   0   0   \n",
       "\n",
       "     R6  R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "537   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "538   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "539   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation set:\")\n",
    "validSetData.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "      <th>R6</th>\n",
       "      <th>R7</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>...</th>\n",
       "      <th>R62</th>\n",
       "      <th>R63</th>\n",
       "      <th>R64</th>\n",
       "      <th>R65</th>\n",
       "      <th>R66</th>\n",
       "      <th>R67</th>\n",
       "      <th>R68</th>\n",
       "      <th>R69</th>\n",
       "      <th>R70</th>\n",
       "      <th>R71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Consider not auto-navigating on drop into omni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>SECURE_WITH_POLICY_INSTALLED_CERT should show ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Fingerprinting via video time information leak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  R1  R2  R3  R4  R5  \\\n",
       "716  Consider not auto-navigating on drop into omni...   0   0   0   0   0   \n",
       "717  SECURE_WITH_POLICY_INSTALLED_CERT should show ...   0   0   0   0   0   \n",
       "718  Fingerprinting via video time information leak...   0   0   0   0   0   \n",
       "\n",
       "     R6  R7  R8  R9  ...  R62  R63  R64  R65  R66  R67  R68  R69  R70  R71  \n",
       "716   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "717   0   0   0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "718   0   0   0   0  ...    0    0    1    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"testset:\")\n",
    "testSetData.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wording embedding layer using pretrained model from Google's word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.0.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.16.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = trainSetData.description\n",
    "validText = validSetData.description\n",
    "testText = testSetData.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5658 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=300000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'', lower=True)\n",
    "tokenizer.fit_on_texts(trainText)\n",
    "trainSequences = tokenizer.texts_to_sequences(trainText)\n",
    "validSequences = tokenizer.texts_to_sequences(validText)\n",
    "testSequences = tokenizer.texts_to_sequences(testText)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train and X validation tensor: (537, 2141) (179, 2141)\n",
      "Shape of label train and validation tensor: (537, 71) (179, 71)\n",
      "Shape of X test: (180, 2141)\n",
      "Shape of label test tensor: (180, 71)\n"
     ]
    }
   ],
   "source": [
    "x_train = pad_sequences(trainSequences)\n",
    "y_train = trainSetData.iloc[:,1:].values\n",
    "\n",
    "x_valid = pad_sequences(validSequences, maxlen = x_train.shape[1])\n",
    "y_valid = validSetData.iloc[:,1:].values\n",
    "\n",
    "x_test = pad_sequences(testSequences,maxlen = x_train.shape[1])\n",
    "y_test = testSetData.iloc[:,1:].values\n",
    "\n",
    "print('Shape of X train and X validation tensor:', x_train.shape, x_valid.shape)\n",
    "print('Shape of label train and validation tensor:', y_train.shape, y_valid.shape)\n",
    "\n",
    "print('Shape of X test:', x_test.shape)\n",
    "print('Shape of label test tensor:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Google's pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ps642\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.23.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(path + 'GoogleNews-vectors-negative300.bin.gz', \n",
    "                                                 binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word not found in pretrained w2v: 1903\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM=300\n",
    "vocabulary_size = min(len(word_index)+1,NUM_WORDS) # minimum fo word index and num words\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "count_word_not_found = 0\n",
    "for word, i in word_index.items():\n",
    "  if i>=NUM_WORDS:\n",
    "    continue\n",
    "  try:\n",
    "    embedding_vector = word_vectors[word]\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "  except KeyError:\n",
    "    embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "    count_word_not_found = count_word_not_found + 1\n",
    "\n",
    "print(\"word not found in pretrained w2v: \" + str(count_word_not_found))\n",
    "# there are many words do not exist in google w2v. we random number for those words.\n",
    "\n",
    "del(word_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2141)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 2141, 300)    1697700     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2141, 300, 1  0           ['embedding[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 2139, 1, 100  90100       ['reshape[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 2138, 1, 100  120100      ['reshape[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 2137, 1, 100  150100      ['reshape[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 1, 100)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 1, 100)    0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 300)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          38528       ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 71)           9159        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,105,687\n",
      "Trainable params: 2,105,687\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "                            \n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout, concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sequence_length = x_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(1,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=(1,1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((3*num_filters,))(flatten)\n",
    "\n",
    "fc_layer = Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "fc_dropout = Dropout(drop)(fc_layer)\n",
    "output = Dense(units=len(y_train[0]), activation='sigmoid', kernel_regularizer=regularizers.l2(0.01))(fc_dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ps642\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path_modelcheckpoint = path\n",
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(path_modelcheckpoint+project+'_ch_.hdf5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.3668 - acc: 0.0670   \n",
      "Epoch 1: val_loss improved from inf to 3.13863, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 38s 11s/step - loss: 3.3668 - acc: 0.0670 - val_loss: 3.1386 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.0850 - acc: 0.0968 \n",
      "Epoch 2: val_loss improved from 3.13863 to 2.85179, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 34s 11s/step - loss: 3.0850 - acc: 0.0968 - val_loss: 2.8518 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.8554 - acc: 0.0633 \n",
      "Epoch 3: val_loss improved from 2.85179 to 2.59892, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 33s 11s/step - loss: 2.8554 - acc: 0.0633 - val_loss: 2.5989 - val_acc: 0.2179 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.6487 - acc: 0.0466 \n",
      "Epoch 4: val_loss improved from 2.59892 to 2.37797, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 34s 11s/step - loss: 2.6487 - acc: 0.0466 - val_loss: 2.3780 - val_acc: 0.0223 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.4479 - acc: 0.0503 \n",
      "Epoch 5: val_loss improved from 2.37797 to 2.19008, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 32s 10s/step - loss: 2.4479 - acc: 0.0503 - val_loss: 2.1901 - val_acc: 0.0056 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.2822 - acc: 0.0335 \n",
      "Epoch 6: val_loss improved from 2.19008 to 2.02917, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 33s 11s/step - loss: 2.2822 - acc: 0.0335 - val_loss: 2.0292 - val_acc: 0.2179 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1144 - acc: 0.0335 \n",
      "Epoch 7: val_loss improved from 2.02917 to 1.88846, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 32s 10s/step - loss: 2.1144 - acc: 0.0335 - val_loss: 1.8885 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.9571 - acc: 0.0466 \n",
      "Epoch 8: val_loss improved from 1.88846 to 1.76339, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.9571 - acc: 0.0466 - val_loss: 1.7634 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8210 - acc: 0.0447 \n",
      "Epoch 9: val_loss improved from 1.76339 to 1.65006, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 30s 9s/step - loss: 1.8210 - acc: 0.0447 - val_loss: 1.6501 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7003 - acc: 0.0689\n",
      "Epoch 10: val_loss improved from 1.65006 to 1.54602, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.7003 - acc: 0.0689 - val_loss: 1.5460 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5837 - acc: 0.0521\n",
      "Epoch 11: val_loss improved from 1.54602 to 1.44963, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.5837 - acc: 0.0521 - val_loss: 1.4496 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4792 - acc: 0.0801\n",
      "Epoch 12: val_loss improved from 1.44963 to 1.35990, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.4792 - acc: 0.0801 - val_loss: 1.3599 - val_acc: 0.2291 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3876 - acc: 0.1080\n",
      "Epoch 13: val_loss improved from 1.35990 to 1.27587, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3876 - acc: 0.1080 - val_loss: 1.2759 - val_acc: 0.2179 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3017 - acc: 0.0894\n",
      "Epoch 14: val_loss improved from 1.27587 to 1.19745, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.3017 - acc: 0.0894 - val_loss: 1.1975 - val_acc: 0.1955 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2202 - acc: 0.0987\n",
      "Epoch 15: val_loss improved from 1.19745 to 1.12368, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.2202 - acc: 0.0987 - val_loss: 1.1237 - val_acc: 0.1676 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1455 - acc: 0.0968\n",
      "Epoch 16: val_loss improved from 1.12368 to 1.05469, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.1455 - acc: 0.0968 - val_loss: 1.0547 - val_acc: 0.2011 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0713 - acc: 0.1453\n",
      "Epoch 17: val_loss improved from 1.05469 to 0.99021, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 19s 6s/step - loss: 1.0713 - acc: 0.1453 - val_loss: 0.9902 - val_acc: 0.1844 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0084 - acc: 0.1397\n",
      "Epoch 18: val_loss improved from 0.99021 to 0.93026, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 1.0084 - acc: 0.1397 - val_loss: 0.9303 - val_acc: 0.1788 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9453 - acc: 0.1490\n",
      "Epoch 19: val_loss improved from 0.93026 to 0.87463, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.9453 - acc: 0.1490 - val_loss: 0.8746 - val_acc: 0.1844 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8930 - acc: 0.1117\n",
      "Epoch 20: val_loss improved from 0.87463 to 0.82277, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.8930 - acc: 0.1117 - val_loss: 0.8228 - val_acc: 0.1620 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8361 - acc: 0.1415\n",
      "Epoch 21: val_loss improved from 0.82277 to 0.77409, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.8361 - acc: 0.1415 - val_loss: 0.7741 - val_acc: 0.1508 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7909 - acc: 0.1229\n",
      "Epoch 22: val_loss improved from 0.77409 to 0.72892, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.7909 - acc: 0.1229 - val_loss: 0.7289 - val_acc: 0.1508 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7481 - acc: 0.1248\n",
      "Epoch 23: val_loss improved from 0.72892 to 0.68728, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.7481 - acc: 0.1248 - val_loss: 0.6873 - val_acc: 0.1508 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7017 - acc: 0.1117\n",
      "Epoch 24: val_loss improved from 0.68728 to 0.64854, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.7017 - acc: 0.1117 - val_loss: 0.6485 - val_acc: 0.1788 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6651 - acc: 0.1378\n",
      "Epoch 25: val_loss improved from 0.64854 to 0.61234, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.6651 - acc: 0.1378 - val_loss: 0.6123 - val_acc: 0.2011 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6296 - acc: 0.1508\n",
      "Epoch 26: val_loss improved from 0.61234 to 0.57868, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.6296 - acc: 0.1508 - val_loss: 0.5787 - val_acc: 0.2235 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5930 - acc: 0.1601\n",
      "Epoch 27: val_loss improved from 0.57868 to 0.54748, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.5930 - acc: 0.1601 - val_loss: 0.5475 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5648 - acc: 0.1583\n",
      "Epoch 28: val_loss improved from 0.54748 to 0.51885, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.5648 - acc: 0.1583 - val_loss: 0.5189 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5339 - acc: 0.1453\n",
      "Epoch 29: val_loss improved from 0.51885 to 0.49236, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.5339 - acc: 0.1453 - val_loss: 0.4924 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5081 - acc: 0.1490\n",
      "Epoch 30: val_loss improved from 0.49236 to 0.46770, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.5081 - acc: 0.1490 - val_loss: 0.4677 - val_acc: 0.2235 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4817 - acc: 0.1304\n",
      "Epoch 31: val_loss improved from 0.46770 to 0.44444, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4817 - acc: 0.1304 - val_loss: 0.4444 - val_acc: 0.1676 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4577 - acc: 0.1359\n",
      "Epoch 32: val_loss improved from 0.44444 to 0.42272, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4577 - acc: 0.1359 - val_loss: 0.4227 - val_acc: 0.1508 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4343 - acc: 0.1713\n",
      "Epoch 33: val_loss improved from 0.42272 to 0.40229, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4343 - acc: 0.1713 - val_loss: 0.4023 - val_acc: 0.1508 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4158 - acc: 0.1415\n",
      "Epoch 34: val_loss improved from 0.40229 to 0.38352, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4158 - acc: 0.1415 - val_loss: 0.3835 - val_acc: 0.1676 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3978 - acc: 0.1899\n",
      "Epoch 35: val_loss improved from 0.38352 to 0.36683, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3978 - acc: 0.1899 - val_loss: 0.3668 - val_acc: 0.2291 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3788 - acc: 0.1434\n",
      "Epoch 36: val_loss improved from 0.36683 to 0.35158, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3788 - acc: 0.1434 - val_loss: 0.3516 - val_acc: 0.1620 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3648 - acc: 0.1359\n",
      "Epoch 37: val_loss improved from 0.35158 to 0.33709, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3648 - acc: 0.1359 - val_loss: 0.3371 - val_acc: 0.2067 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3478 - acc: 0.1601\n",
      "Epoch 38: val_loss improved from 0.33709 to 0.32309, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3478 - acc: 0.1601 - val_loss: 0.3231 - val_acc: 0.1620 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3343 - acc: 0.1583\n",
      "Epoch 39: val_loss improved from 0.32309 to 0.30983, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3343 - acc: 0.1583 - val_loss: 0.3098 - val_acc: 0.1788 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3196 - acc: 0.1713\n",
      "Epoch 40: val_loss improved from 0.30983 to 0.29790, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3196 - acc: 0.1713 - val_loss: 0.2979 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3089 - acc: 0.1527\n",
      "Epoch 41: val_loss improved from 0.29790 to 0.28736, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.3089 - acc: 0.1527 - val_loss: 0.2874 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2967 - acc: 0.1657\n",
      "Epoch 42: val_loss improved from 0.28736 to 0.27742, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2967 - acc: 0.1657 - val_loss: 0.2774 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2859 - acc: 0.1676\n",
      "Epoch 43: val_loss improved from 0.27742 to 0.26784, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2859 - acc: 0.1676 - val_loss: 0.2678 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2765 - acc: 0.1713\n",
      "Epoch 44: val_loss improved from 0.26784 to 0.25866, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2765 - acc: 0.1713 - val_loss: 0.2587 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2682 - acc: 0.1620\n",
      "Epoch 45: val_loss improved from 0.25866 to 0.25017, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2682 - acc: 0.1620 - val_loss: 0.2502 - val_acc: 0.2123 - lr: 0.0010\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2590 - acc: 0.1583\n",
      "Epoch 46: val_loss improved from 0.25017 to 0.24269, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2590 - acc: 0.1583 - val_loss: 0.2427 - val_acc: 0.1732 - lr: 0.0010\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2512 - acc: 0.1862\n",
      "Epoch 47: val_loss improved from 0.24269 to 0.23576, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2512 - acc: 0.1862 - val_loss: 0.2358 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2445 - acc: 0.1769\n",
      "Epoch 48: val_loss improved from 0.23576 to 0.22960, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2445 - acc: 0.1769 - val_loss: 0.2296 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2371 - acc: 0.1750\n",
      "Epoch 49: val_loss improved from 0.22960 to 0.22301, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2371 - acc: 0.1750 - val_loss: 0.2230 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2303 - acc: 0.2104\n",
      "Epoch 50: val_loss improved from 0.22301 to 0.21680, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2303 - acc: 0.2104 - val_loss: 0.2168 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2240 - acc: 0.1955\n",
      "Epoch 51: val_loss improved from 0.21680 to 0.21148, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2240 - acc: 0.1955 - val_loss: 0.2115 - val_acc: 0.2235 - lr: 0.0010\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2193 - acc: 0.1695\n",
      "Epoch 52: val_loss improved from 0.21148 to 0.20658, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2193 - acc: 0.1695 - val_loss: 0.2066 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2131 - acc: 0.1825\n",
      "Epoch 53: val_loss improved from 0.20658 to 0.20212, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2131 - acc: 0.1825 - val_loss: 0.2021 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2080 - acc: 0.1918\n",
      "Epoch 54: val_loss improved from 0.20212 to 0.19807, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2080 - acc: 0.1918 - val_loss: 0.1981 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2045 - acc: 0.1732\n",
      "Epoch 55: val_loss improved from 0.19807 to 0.19369, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.2045 - acc: 0.1732 - val_loss: 0.1937 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1999 - acc: 0.1937\n",
      "Epoch 56: val_loss improved from 0.19369 to 0.18977, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.1999 - acc: 0.1937 - val_loss: 0.1898 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1967 - acc: 0.1695\n",
      "Epoch 57: val_loss improved from 0.18977 to 0.18611, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.1967 - acc: 0.1695 - val_loss: 0.1861 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1924 - acc: 0.1769\n",
      "Epoch 58: val_loss improved from 0.18611 to 0.18256, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.1924 - acc: 0.1769 - val_loss: 0.1826 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1884 - acc: 0.1937\n",
      "Epoch 59: val_loss improved from 0.18256 to 0.17964, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.1884 - acc: 0.1937 - val_loss: 0.1796 - val_acc: 0.2346 - lr: 0.0010\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1855 - acc: 0.2067\n",
      "Epoch 60: val_loss improved from 0.17964 to 0.17675, saving model to C:/Users/ps642/Desktop/cnn\\Chrome_reg_level_ch_.hdf5\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.1855 - acc: 0.2067 - val_loss: 0.1768 - val_acc: 0.2346 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x_train, y_train, batch_size=200, epochs=60, verbose=1, validation_data=(x_valid, y_valid), \n",
    "                             callbacks=[early_stopping, model_checkpoint, reduce_lr_loss])  # starts training\n",
    "\n",
    "#change epoch here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ps642/Desktop/cnn/training_history/\n"
     ]
    }
   ],
   "source": [
    "path_history = path_modelcheckpoint + 'training_history/'\n",
    "print(path_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "path_history = path_modelcheckpoint + 'training_history/'\n",
    "path_model_json = path_modelcheckpoint + 'model_structure/'\n",
    "path_model_weight = path_modelcheckpoint + 'model_weight/'\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(training_history.history) \n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = path_history+project+'_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# save the best model\n",
    "# save model structure\n",
    "model_json = model.to_json()\n",
    "with open(path_model_json+project+\"_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# save model weight\n",
    "model.save_weights(path_model_weight+project+\"_wieght.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a recommendation on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 186ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_log = path\n",
    "\n",
    "np.savetxt(path_log + project + \"_actual.csv\", y_test, delimiter=\",\")\n",
    "np.savetxt(path_log + project + \"_estimate.csv\", y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, estimate, startK, stopK, stepK):\n",
    "    recall_k = []\n",
    "    for k in range(startK, stopK + 1, stepK):\n",
    "        if k == 0:\n",
    "            k = 1\n",
    "        m = len(actual)\n",
    "        sum_recall = 0.0\n",
    "        for j in range(len(actual)):\n",
    "            y_true = np.argwhere(actual[j])\n",
    "            y_pred = estimate[j].argsort()[-k:]\n",
    "            # print y_true\n",
    "            # print y_pred\n",
    "            intersect = (y_true == y_pred).sum()\n",
    "            # print intersect\n",
    "            # print (len(y_true))\n",
    "            # print intersect / float(len(y_true))\n",
    "            sum_recall = sum_recall + (intersect / float(len(y_true)))\n",
    "            # print sum_recall\n",
    "        recall_k.append(sum_recall / float(m))\n",
    "        # print m\n",
    "        print('Recall@' + str(k) + ': {:.4f}'.format(sum_recall / float(m)))\n",
    "    return recall_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project:Chrome_reg_level\n",
      "Recall@1: 0.1606\n",
      "Recall@2: 0.4532\n",
      "Recall@3: 0.5505\n",
      "Recall@4: 0.7014\n",
      "Recall@5: 0.7477\n",
      "Recall@6: 0.7810\n",
      "Recall@7: 0.8171\n",
      "Recall@8: 0.8671\n",
      "Recall@9: 0.9130\n",
      "Recall@10: 0.9213\n",
      "Recall@11: 0.9241\n",
      "Recall@12: 0.9394\n",
      "Recall@13: 0.9449\n",
      "Recall@14: 0.9468\n",
      "Recall@15: 0.9523\n",
      "Recall@16: 0.9579\n",
      "Recall@17: 0.9579\n",
      "Recall@18: 0.9579\n",
      "Recall@19: 0.9579\n",
      "Recall@20: 0.9690\n",
      "Recall@21: 0.9745\n",
      "Recall@22: 0.9745\n",
      "Recall@23: 0.9745\n",
      "Recall@24: 0.9745\n",
      "Recall@25: 0.9764\n",
      "Recall@26: 0.9764\n",
      "Recall@27: 0.9764\n",
      "Recall@28: 0.9764\n",
      "Recall@29: 0.9764\n",
      "Recall@30: 0.9764\n",
      "Recall@31: 0.9764\n",
      "Recall@32: 0.9875\n",
      "Recall@33: 0.9875\n",
      "Recall@34: 0.9875\n",
      "Recall@35: 0.9875\n",
      "Recall@36: 0.9875\n",
      "Recall@37: 0.9875\n",
      "Recall@38: 0.9875\n",
      "Recall@39: 0.9875\n",
      "Recall@40: 0.9875\n",
      "Recall@41: 0.9875\n",
      "Recall@42: 0.9875\n",
      "Recall@43: 0.9875\n",
      "Recall@44: 0.9875\n",
      "Recall@45: 0.9875\n",
      "Recall@46: 0.9875\n",
      "Recall@47: 0.9875\n",
      "Recall@48: 0.9875\n",
      "Recall@49: 0.9875\n",
      "Recall@50: 0.9875\n",
      "Recall@51: 0.9875\n",
      "Recall@52: 0.9875\n",
      "Recall@53: 0.9875\n",
      "Recall@54: 0.9875\n",
      "Recall@55: 0.9875\n",
      "Recall@56: 0.9875\n",
      "Recall@57: 0.9875\n",
      "Recall@58: 0.9907\n",
      "Recall@59: 0.9907\n",
      "Recall@60: 0.9907\n",
      "Recall@61: 0.9907\n",
      "Recall@62: 0.9935\n",
      "Recall@63: 0.9935\n",
      "Recall@64: 0.9935\n",
      "Recall@65: 0.9935\n",
      "Recall@66: 0.9935\n",
      "Recall@67: 0.9935\n",
      "Recall@68: 1.0000\n",
      "Recall@69: 1.0000\n",
      "Recall@70: 1.0000\n",
      "Recall@71: 1.0000\n"
     ]
    }
   ],
   "source": [
    "startK = 1\n",
    "stepK = 1\n",
    "stopK = 71\n",
    "\n",
    "print(\"Project:\" + project)\n",
    "\n",
    "path_output = path\n",
    "\n",
    "recall_k = recall(y_test, y_pred, startK, stopK, stepK)\n",
    "\n",
    "np.savetxt(path_output + project + \"_recall_\" + str(startK) + \"_\" + str(stopK)+ \"_v.csv\", recall_k, delimiter=\",\", fmt='%1.4f')\n",
    "with open(path_output + \"performance\" + \"_recall_\" + str(startK) + \"_\" + str(stopK)+ \".csv\", 'a') as myoutput:\n",
    "  myoutput.write(project + \",\" + \",\".join(map(str, recall_k)) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.2000',\n",
       " '0.2611',\n",
       " '0.2167',\n",
       " '0.2069',\n",
       " '0.1778',\n",
       " '0.1556',\n",
       " '0.1389',\n",
       " '0.1292',\n",
       " '0.1210',\n",
       " '0.1100',\n",
       " '0.1005',\n",
       " '0.0940',\n",
       " '0.0876',\n",
       " '0.0817',\n",
       " '0.0770',\n",
       " '0.0726',\n",
       " '0.0683',\n",
       " '0.0645',\n",
       " '0.0611',\n",
       " '0.0586',\n",
       " '0.0561',\n",
       " '0.0535',\n",
       " '0.0512',\n",
       " '0.0491',\n",
       " '0.0473',\n",
       " '0.0455',\n",
       " '0.0438',\n",
       " '0.0423',\n",
       " '0.0408',\n",
       " '0.0394',\n",
       " '0.0382',\n",
       " '0.0375',\n",
       " '0.0364',\n",
       " '0.0353',\n",
       " '0.0343',\n",
       " '0.0333',\n",
       " '0.0324',\n",
       " '0.0316',\n",
       " '0.0308',\n",
       " '0.0300',\n",
       " '0.0293',\n",
       " '0.0286',\n",
       " '0.0279',\n",
       " '0.0273',\n",
       " '0.0267',\n",
       " '0.0261',\n",
       " '0.0255',\n",
       " '0.0250',\n",
       " '0.0245',\n",
       " '0.0240',\n",
       " '0.0235',\n",
       " '0.0231',\n",
       " '0.0226',\n",
       " '0.0222',\n",
       " '0.0218',\n",
       " '0.0214',\n",
       " '0.0211',\n",
       " '0.0209',\n",
       " '0.0205',\n",
       " '0.0202',\n",
       " '0.0199',\n",
       " '0.0196',\n",
       " '0.0193',\n",
       " '0.0190',\n",
       " '0.0187',\n",
       " '0.0184',\n",
       " '0.0182',\n",
       " '0.0181',\n",
       " '0.0179',\n",
       " '0.0176',\n",
       " '0.0174']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = y_test \n",
    "estimate = y_pred\n",
    "\n",
    "def prepare_y(actual, estimate, k):\n",
    "    y_true = np.argwhere(actual)\n",
    "    y_pred = estimate.argsort()[-k:]\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "precision_at_k = []\n",
    "component_num = len(actual.T)\n",
    "\n",
    "for k in range(component_num):\n",
    "    sum_precision = 0.0\n",
    "    for j in range(len(actual)):\n",
    "        y_true, y_pred = prepare_y(actual[j], estimate[j], (k + 1))\n",
    "        relevant = (y_true == y_pred).sum()\n",
    "        total_recommended_item = k + 1\n",
    "        sum_precision = sum_precision + (float(relevant) / total_recommended_item)\n",
    "\n",
    "    precision_at_k.append('%.4f' % (sum_precision / len(actual)))\n",
    "    # print('Precision@K: {:.4f}'.format(sum_precision / len(actual)))\n",
    "\n",
    "print(\"Precision@k\")\n",
    "\n",
    "precision_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: Chrome_reg_level, Model: <keras.engine.functional.Functional object at 0x000001ABA5BA0340>\n",
      "MAP: 0.193326 over 180.0000 issues\n"
     ]
    }
   ],
   "source": [
    "m = len(actual)\n",
    "sum = 0.0\n",
    "for j in range(len(actual)):\n",
    "    y_true = np.argwhere(actual[j])\n",
    "    tp = len(y_true)\n",
    "    psum = 0.0\n",
    "    for k in range(1, tp + 1):\n",
    "        y_pred = estimate[j].argsort()[-k:]\n",
    "        intersect = (y_true == y_pred).sum()\n",
    "        prec = intersect / float(k)\n",
    "        psum += prec\n",
    "    ap = psum / float(tp)\n",
    "    sum += ap\n",
    "mean_avg_prec = sum / float(m)\n",
    "print('Project: {}, Model: {}'.format(project, model))\n",
    "print('MAP: {:f} over {:.4f} issues'.format(mean_avg_prec, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: Chrome_reg_level, Model: <keras.engine.functional.Functional object at 0x000001ABA5BA0340>\n",
      "MRR: 0.456072 over 180.0000 issues\n"
     ]
    }
   ],
   "source": [
    "sum_rr = 0.0\n",
    "m = len(actual)\n",
    "for j in range(len(actual)):\n",
    "    y_true = np.argwhere(actual[j])\n",
    "    y_pred = estimate[j].argsort()[::-1][:]\n",
    "    ranks = []\n",
    "    for idx, i in enumerate(y_pred):\n",
    "        if i in y_true:\n",
    "            ranks.append(idx + 1)\n",
    "    if len(ranks) > 0:\n",
    "        first = ranks[0]\n",
    "        rr = 1 / float(first)\n",
    "        sum_rr += rr\n",
    "mrr_score = sum_rr / float(m)\n",
    "print('Project: {}, Model: {}'.format(project, model))\n",
    "print('MRR: {:f} over {:.4f} issues'.format(mrr_score, m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
